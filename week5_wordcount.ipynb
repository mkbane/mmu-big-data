{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week5-wordcount.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN5aNQAg8K6D72uwoIuDX81"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WA9IMxEzp91X"
      },
      "outputs": [],
      "source": [
        "# list files (note the \"!\" to make this a unix/linux command)\n",
        "# if we only see \"sample_data\" then this is a new instance and we need to do steps 2 and 3 to get/install files\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# step 2: set-up spark (NB if Apache amend versions on download site we will need to amend path in wget command)\n",
        "!clear\n",
        "!echo welcome\n",
        "!ls\n",
        "!rm -f spark-3.2.[01]-bin-hadoop3.2.tgz* \n",
        "!rm -rf spark-3.2.[01]-bin-hadoop3.2\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar -xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!ls -alt"
      ],
      "metadata": {
        "id": "2K7DYWwCqFBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 3: wget example file for word count\n",
        "!wget https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\n",
        "!ls"
      ],
      "metadata": {
        "id": "eaYCw8S3qTOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init spark (ensure SPARK_HOME set to same version as we download earlier)\n",
        "!pip3 install findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark import SparkConf, SparkContext\n",
        "# the next line gives us 'local' mode. try 'local[2]' to use 2 cores or 'master:NNNN' to run on Spark standalone cluster at port NNNN\n",
        "spark_conf = SparkConf().setMaster('local[4]').setAppName('MyApp')\n",
        "sc = SparkContext(conf=spark_conf)\n",
        "# see what we have by examining the Spark User Interface\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "vKS9NWV-1V5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RDD EXAMPLE of wordcount"
      ],
      "metadata": {
        "id": "w7BuH7lOspBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = sc.textFile(\"t8.shakespeare.txt\")\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")) \\\n",
        "             .map(lambda word: (word, 1)) \\\n",
        "             .reduceByKey(lambda a, b: a + b)\n",
        "counts.saveAsTextFile(\"counts_via_RDD.txt\")  # will not overwrite output file\n",
        "\n",
        " # in above note the use of \"lambda algebra\" to operate at low level on RDDs"
      ],
      "metadata": {
        "id": "JHSPeHVosq3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DF EXAMPLE of wordcount"
      ],
      "metadata": {
        "id": "ioTe6U0_sukO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"words\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "ExOXxCFahxNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = spark.read.text(\"t8.shakespeare.txt\")"
      ],
      "metadata": {
        "id": "L59MpDv012QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input.show()"
      ],
      "metadata": {
        "id": "Cnsrwy0GkREp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split input (by line) into words by presuming space is delimiter, set alias \"word\" to column of results\n",
        "words = input.select(explode(split(input.value, \" \")).alias(\"word\"))"
      ],
      "metadata": {
        "id": "ygBwa8DTkrbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words.show()"
      ],
      "metadata": {
        "id": "3aoAMHonlser"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group by unique word and count how many\n",
        "wordCount = words.groupBy(\"word\").count()"
      ],
      "metadata": {
        "id": "pF6ZsMVllt6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordCount.show()"
      ],
      "metadata": {
        "id": "JJQh-h_Zl2sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... and sort\n",
        "words.groupBy(\"word\").count().sort(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "id": "qJ9mTIfrl4b-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# illustrates orderBy as alternative to sort\n",
        "words.groupBy(\"word\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "id": "2Y-05POinDqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g2kwo2iRpJ2Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}